6.885 Lecture 6 (Data Cleaning and Integration #4) - 9/24/13

**ENTITY RESOLUTION**
- take two data sets and see if two database records in both sets are actually the same object.

- Approximate match, deduplication, record linking

Problems to consider
- mismatched data
- missing data
- variations in representation

How are we doing in terms of entity resolution?
- IDEA: need to get some ground truth data.
- METRICS:
  - True Positives
    - count the number of correct matches we got
  - False Positives
    - things that we said matched but don't match in ground truth
  - False Negatives
    - number of things that were matched in ground truth but not matched in our algorithm

PRECISION
  - the number of True Positives(?)
    - but want it to be a number between 0 and 1.
      - 0 = none of our matches were correct matches
      - 1 = all of our matches were correct matches
  - so actually, PERCENT ACCURACY
    - equal to (True Positive) / (True Positive + False Positive)

RECALL
  - equal to (True Positive) / (Data Set Size)

F-MEASURE
  - a way to combine precision and recall
  - you could take an average of precision and recall
    - very low precision and very high recall would be the same as if they were both average.
  - the way you actually do it is HARMONIC MEAN
    - (2 * precision * recall) / (precision + recall)

Entity Resolution Algorithms
- attribute matching algorithms
  - exact match
  - edit distance
    - the number of insertions/deletions/modifications you have to do to go from A to B
  - Jaccard similarity - similarity between sets
    - s1 = words in string 1
    - s2 = words in string 2
    - Jaccard Similarity = |S1 ^ S2| / |S1 U S2|
  - Can also do Jaccard Similarity + Thesaurus
  - Also can do Jaccard Similarity + n-grams
  - Canonicalization
  
**IN CLASS EXAMPLE**
f = 0.497

Limitations 
  - sample score
    - we can use other attributes, features
  - quadratic
  - threshold - incomplete search

Machine Learning will allow us to combine simple score and threshold.
- Decision Trees/Support Vectors Machines
  - you have a graph of positive and negative items from training data - you want to find the divider that best separates the two
  - find the divider that minimizes the entropy on the two subsets

**REST OF MACHINE LEARNING STUFF NEXT TIME**
